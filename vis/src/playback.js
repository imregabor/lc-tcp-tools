'use strict';

/*
 * Contents are based on repo https://github.com/mdn/webaudio-examples
 * published under `CC0-1.0 license` (see
 * https://github.com/mdn/webaudio-examples/blob/41775fb3e0dbaaf27f643b5e9937f1ec2993badd/LICENSE ).
 */

import './playback.css';
import * as u from './util.js';
import * as d3 from 'd3';
import '@fortawesome/fontawesome-free/css/all.css'
import * as mp3dialog from './mp3-select-dialog.js';
import * as apiClient from './api-client.js';
import * as notes from './notes.js';
import * as ed from './ed.js';

export function addPlaybackControls(parentD3, opts) {
  apiClient.getMp3Servers(mp3dialog.loadMp3ListFromServer);

  const d = parentD3.append('div').classed('playback-extra-controls', true);
  const i1 = d.append('i')
      .classed('fa fa-folder-open fa-fw', true)
      .attr('title', 'Play from music collection')
      .on('click', () => {
        mp3dialog.chooseMp3()
            .then(url => opts.startPlaybackFrom(url))
            .catch(e => {
              console.log('Error in mp3 dialog', e);
            });
      });
  d.append('i')
      .classed('fa fa-microphone fa-fw', true)
      .attr('title', 'Capture audio')
      .on('click', () => {
        /*
        navigator.mediaDevices.getUserMedia({
          audio: true,
        }).then((stream) => {});
        */

        navigator.mediaDevices.enumerateDevices()
            .then(devices => {
              console.log('Devices', devices);
              const resolveList = [];
              devices.forEach(d => {
                if (d.kind !== 'audioinput') {
                  return;
                }
                resolveList.push({
                  mediaDeviceId : d.deviceId,
                  mediaDeviceLabel : d.label,
                  t1 : d.label,
                  t2 : `deviceId: ${d.deviceId}, groupId: ${d.groupId}`
                });
              });

              mp3dialog
                  .showModal({
                    title : 'Select capture device',
                    resolve : v => opts.startCapture(v.mediaDeviceId, v.mediaDeviceLabel)
                  })
                  .appendResolvingList(resolveList, d => d.t1, d => d.t2);
            });

      });

  const i2 = d.append('i')
      .classed('fa fa-ellipsis-h fa-fw', true)
      .attr('title', 'Pick other audio source')
      .on('click', () => {
        mp3dialog
            .showModal({
              title : 'Pick audio source',
              resolve : v => {
                console.log('Pick audio resolved', v);
                if (v.dmp3) {
                  opts.startDecodeFrom(v.dmp3);
                } else if (v.tone) {
                  opts.tone(v.tone);
                }
              }
            })
            .appendH2('Decoded MP3')
            .appendP('Audio samples stored locally (no MP3 server dependency), decoded into a buffer before playback.')
            .appendResolvingList([
              { dmp3 : 'data/viper.mp3' , t1 : 'Viper', t2 : 'for Web Audio examples project' },
              // track credit:
              // Outfoxing the Fox by Kevin MacLeod under Creative Commons
              { dmp3 : 'data/outfoxing.mp3' , t1 : 'Outfoxing the fox', t2 : 'by Kevin MacLeod (incompetech.com)' },
              // track credit:
              // RetroFuture Dirty Kevin MacLeod (incompetech.com)
              // Licensed under Creative Commons: By Attribution 3.0 License http://creativecommons.org/ licenses/by/3.0/
              { dmp3 : 'data/retrofuturedirty.mp3' , t1 : 'RetroFuture dirty', t2 : 'by Kevin MacLeod (incompetech.com)' },
              // track credit:
              // "Sneaky Snitch" Kevin MacLeod (incompetech.com)
              // Licensed under Creative Commons: By Attribution 4.0 License http://creativecommons.org/licenses/by/4.0/
              { dmp3 : 'data/sneakysnitch.mp3' , t1 : 'Sneaky Snitch', t2 : 'by Kevin MacLeod (incompetech.com)' }
            ], d => d.t1, d => d.t2)
            .appendH2('Fixed tones')
            .appendP('Pure sine wave(s) generated by oscillator node.')
            .appendResolvingList([
              { tone : 16.35160, desc : 'C0, first (white) key on an extended, 108-key piano' },
              { tone : 27.5, desc : 'A0, first (white) key on a 88-key piano' },
              { tone : 29.13524, desc : 'A#0 / Bb0, first black key on a 88-key piano' },
              { tone : 55, desc : 'A1' },
              { tone : 110, desc : 'A2' },
              { tone : 220, desc : 'A3' },
              { tone : 415.3047, desc : 'G#4 / Ab4, black key below A4' },
              { tone : 440, desc : 'A4 / A440, aka Stuttgart pitch' },
              { tone : 466.1638, desc : 'A#4 / Bb4, black key above A4' },
              { tone : 880, desc : 'A5' },
              { tone : 1000 },
              { tone : 1760, desc : 'A6' },
              { tone : 3520, desc : 'A7' },
              { tone : 3729.310, desc : 'A#7 . Bb7, last black key on a 88-key piano' },
              { tone : 4186.009, desc : 'C8, last (white) key on a 88-key piano' },
              { tone : 7902.133, desc : 'B8, last (white) key on an extended, 108-key piano' },
              { tone : [ 27.5, 55, 110, 220, 440, 880, 1760, 3520 ], desc : 'Polyphonic, A0 - A7' }
            ], d => `${d.tone} Hz`, d => d.desc ? d.desc : '');
      });

  const i3 = d.append('i')
      .classed('fa fa-stop fa-fw', true)
      .attr('title', 'Stop playback')
      .on('click', () => {
        opts.stop();
      });
  i3.classed('disabled', true);

  const ret = {
    stopEnabled : v => i3.classed('disabled', !v)
  };
  return ret;
}

/**
 * Add playback.
 *
 * parentD3: D3 selection of parent element for buttons
 * playerParentD3: D3 selection of parent element for audio element and additional seek controls
 */
export function addSimplePlayback(parentD3, playerParentD3, msgD3) {
  const ctrls = addPlaybackControls(parentD3, {
    startPlaybackFrom : url => audio(url),
    startDecodeFrom : url => load(url),
    startCapture : (deviceId, deviceLabel) => startCapture(deviceId, deviceLabel),
    tone : f => tone(f),
    stop : () => stop()
  });

  if (msgD3) {
    msgD3 = msgD3.append('span');
  }

  /*
  const div = parentD3.append('div').classed('playback-controls', true);
  const msgDiv = div.append('div').classed('message', true)
  const msg1 = msgDiv.append('span').text('Click on a play button');
  const msg2 = msgDiv.append('span');
  */

  var audioContext;
  var sourceNode;
  var sourceNodes;
  var userMediaStream;
  var sampleRate;
  var playing = false;

  const events = {
    contextCreated : ed.ed(),
    playbackStarted : ed.ed(),
    playbackStopped : ed.ed(),
    playbackPaused : ed.ed(),
    playbackResumed : ed.ed()
  };

  function ensureAudioContext() {
    if (!audioContext) {
      audioContext = new AudioContext({ latencyHint: 0 });
      console.log('AudioContext created, baseLatency:', audioContext.baseLatency);
    }
  }

  function disableButtons() {
    ctrls.stopEnabled(true);
  }

  function enableButtons() {
    ctrls.stopEnabled(false);
  }

  var useAudio = false;

  var a;
  var adiv;
  var apaused;
  var lastPlaybackInfo;
  var astop;

  function audio(url) {
    ret.ensureStop(true);
    message(`Start playing from ${decodeURI(url)}`);
    disableButtons();
    adiv = playerParentD3.append('div').classed('playback-player', true)
    a = adiv.append('audio').attr('crossorigin', 'anonymous').attr('controls', true);
    apaused = false;
    astop = false;

    a.node().onpause = e => {
      if (astop) {
        return;
      }
      apaused = true;
      events.playbackPaused(ret);
    };
    a.node().onplay = e => {
      if (!apaused) {
        return;
      }
      apaused = false;
      events.playbackResumed(ret);
    };
    a.attr('src', url);


    const xctd = adiv.append('div').classed('playback-extra-controls spaced', true);
    xctd.append('i').classed('fa fa-caret-left fa-fw', true).on('click', () => {
      const ct = a.node().currentTime;
      a.node().currentTime = Math.max(0, ct - 3);
      a.node().play();
    });

    xctd.append('i').classed('fa fa-caret-right fa-fw', true).on('click', () => {
      const ct = a.node().currentTime;
      a.node().currentTime = ct + 3;
      a.node().play();
    });

    //audioContext = new AudioContext();
    ensureAudioContext();

    sourceNode = audioContext.createMediaElementSource(a.node());
    sourceNode.connect(audioContext.destination);

    sampleRate = audioContext.sampleRate;

    events.contextCreated(ret);

    useAudio = true;

    lastPlaybackInfo = {
      audio : 'MP3',
      url : url
    };

    ret.start();

  }

  function startCapture(deviceId, deviceLabel) {
    message(`Start capture from ${deviceLabel}`);
    ret.ensureStop(true);
    disableButtons();
    ensureAudioContext();

    navigator.mediaDevices
        .getUserMedia({ audio : { deviceId : deviceId} })
        .then(stream => {
          userMediaStream = stream;
          sourceNode = audioContext.createMediaStreamSource(stream);
          sampleRate = audioContext.sampleRate;

          events.contextCreated(ret);
          lastPlaybackInfo = {
            audio : `Capture from ${deviceLabel}`
          };

          ret.start();
        });
  }

  function tone(f) {
    ret.ensureStop(true);
    var msg;
    var pbinfo;
    if (f instanceof Array) {
      msg = `Playing multiple sinewaves at ${f} Hz`;
      pbinfo = `Sinewaves at ${f} Hz`;
    } else {
      msg = `Playing ${f} Hz sinewave`;
      pbinfo = `${f} z sinewave`;
    }
    message(msg);
    disableButtons();

    // A user interaction happened we can create the audioContext
    // audioContext = new AudioContext();
    ensureAudioContext();

    if (f instanceof Array) {
      sourceNodes = [];
      for (var i = 0; i < f.length; i++) {
        const node = audioContext.createOscillator();
        node.frequency.setValueAtTime(f[i], audioContext.currentTime);
        node.connect(audioContext.destination);
        if (i == 0) {
          sourceNode = node;
        } else {
          sourceNodes.push(node);
        }
      }
    } else {
      sourceNode = audioContext.createOscillator();
      sourceNode.frequency.setValueAtTime(f, audioContext.currentTime);
      sourceNode.connect(audioContext.destination);
    }
    sampleRate = audioContext.sampleRate;



    events.contextCreated(ret);

    lastPlaybackInfo = {
      audio : pbinfo
    };

    ret.start();
  }

  function stop(silent) {
    lastPlaybackInfo = undefined;
    astop = true;
    if (!playing) {
      throw new Error('Not playing');
    }
    playing = false;
    apaused = false;
    if (useAudio) {
      useAudio = false;
      a.node().pause();
      adiv.remove();
      a = undefined;
      adiv = undefined;
    } else if (userMediaStream) {
      if (userMediaStream.stop) {
        userMediaStream.stop();
      } else {
        userMediaStream.getTracks().forEach(track => track.stop());
      }
      userMediaStream = undefined;
    } else {
      sourceNode.stop(0);
      if (sourceNodes) {
        sourceNodes.forEach(n => n.stop(0));
        sourceNodes = undefined;
      }
    }
    enableButtons();
    if (!silent) {
      message2('Playback stopped');
    }
    events.playbackStopped(ret);

  }

  var lastM1;

  function message(message) {
    lastM1 = message;
    if (msgD3) {
      msgD3.text(message);
    } else {
      notes.top(message);
    }
    //msg1.text(message);
     // msg2.text('');
  }

  function message2(message) {
    if (msgD3) {
      msgD3.text(lastM1 + ' | ' + message);
    } else {
      notes.top(message);
    }
    // msg2.text(message);
  }


  function load(url) {
    ret.ensureStop(true);

    disableButtons();

    // A user interaction happened we can create the audioContext
    // audioContext = new AudioContext();
    ensureAudioContext();

    message(`Loading audio from ${url}`);

    fetch(url)
        .then(response => response.arrayBuffer())
        .then(downloadedBuffer => {
          message(`Loaded ${downloadedBuffer.byteLength} bytes, start decoding`);
          return audioContext.decodeAudioData(downloadedBuffer)
        })
        .then((decodedBuffer) => {
          sampleRate = decodedBuffer.sampleRate;
          message(`Decoded ${u.niceRound(decodedBuffer.duration)} s, ${decodedBuffer.numberOfChannels} ch, with sample rate ${decodedBuffer.sampleRate}.`)

          sourceNode = new AudioBufferSourceNode(audioContext, {
            buffer: decodedBuffer,
            loop: true,
          });
          sourceNode.connect(audioContext.destination);

        })
        .then(() => {
          events.contextCreated(ret);

          lastPlaybackInfo = {
            audio : 'MP3 (decoded from buffer)',
            url : url
          };

          ret.start();
        });
  }

  const ret = {
    // signal processing graph / analyzer nodes should be initialized
    // audioContext handling needs rework
    //  - callback called when starting any playback; previous analyzer nodes are not disposed
    //  - should reuse them, see https://developer.mozilla.org/en-US/docs/Web/API/AudioContext
    //    > It's recommended to create one AudioContext and reuse it instead of initializing a new one each time
    onContextCreated : h => {
      events.contextCreated.add(h);
      return ret;
    },
    // playback events will be called with an argument of "ret"
    onPlaybackStarted : h => {
      events.playbackStarted.add(h);
      return ret;
    },
    onPlaybackStopped : h => {
      events.playbackStopped.add(h);
      return ret;
    },
    onPlaybackPaused : h => {
      events.playbackPaused.add(h);
      return ret;
    },
    onPlaybackResumed : h => {
      events.playbackResumed.add(h);
      return ret;
    },
    tryToCreateAudioContext : () => ensureAudioContext(),
    startPlaybackFrom : url => {
      console.log('Start playback from', url)
      if (playing) {
        stop();
      }
      audio(url);
    },
    start : () => {
      if (playing) {
        throw new Error('Already playing');
      }
      if (!sourceNode) {
        throw new Error('No audio loaded');
      }

      if (useAudio) {
        a.node().play();
      } else if (!userMediaStream) {
        sourceNode.start(0);
        if (sourceNodes) {
          sourceNodes.forEach(n => n.start(0));
        }
      }


      playing = true;
      message2('Playback started');
      events.playbackStarted(ret);
    },
    ensureStop : (silent) => {
      if (!playing) {
        return;
      }
      stop(silent);
    },
    newAnalyserNode : () => {
      if (!audioContext) {
        throw new Error('No audio loaded');
      }
      // see https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode
      const analyserNode = new AnalyserNode(audioContext);
      sourceNode.connect(analyserNode);
      if (sourceNodes) {
        sourceNodes.forEach(n => n.connect(analyserNode));
      }
      return analyserNode;
    },
    sampleRate : () => sampleRate,
    getCurrentTime : () => {
      if (!playing) {
        return 0;
      }
      if (useAudio) {
        return a.node().currentTime;
      }
      return 0;
    },
    getDuration : () => {
      if (!playing) {
        return 0;
      }
      if (useAudio) {
        const d = a.node().duration;
        if (d) {
          return d;
        }
      }
      return 0;
    },
    getPlaybackInfo : () => {
      if (!playing) {
        return undefined;
      }
      lastPlaybackInfo.paused = ret.isPaused();
      return lastPlaybackInfo;
    },
    isPlaying : () => playing,
    isPaused : () => apaused,
    pause : () => {
      if (!playing || !useAudio) {
        return;
      }
      a.node().pause();
    },
    resume : () => {
      if (!playing || !useAudio) {
        return;
      }
      a.node().play();
    },
    seek : t => {
      // console.log('Seek to ' + t);
      if (t < 0 || !playing || !useAudio) {
        return;
      }

      a.node().currentTime = t;

      return ret;
    },
    seekRelative : d => {
      // console.log('Seek to ' + t);
      if (!d || !playing || !useAudio) {
        return ret;
      }
      const t = a.node().currentTime;
      if (!t) {
        return ret;
      }
      const nt = t + d;
      a.node().currentTime = nt;
      return ret;
    }
  };
  return ret;
}
