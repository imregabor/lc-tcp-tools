'use strict';

/*
 * Contents are based on repo https://github.com/mdn/webaudio-examples
 * published under `CC0-1.0 license` (see
 * https://github.com/mdn/webaudio-examples/blob/41775fb3e0dbaaf27f643b5e9937f1ec2993badd/LICENSE ).
 */

import './playback.css';
import * as u from './util.js';
import * as d3 from 'd3';
import '@fortawesome/fontawesome-free/css/all.css'
import * as mp3dialog from './mp3-select-dialog.js';
import * as apiClient from './api-client.js';
import * as notes from './notes.js';
import * as ed from './ed.js';

export function addPlaybackControls(parentD3, opts) {
  apiClient.getMp3Servers(mp3dialog.loadMp3ListFromServer);

  const d = parentD3.append('div').classed('playback-extra-controls', true);
  const i1 = d.append('i')
      .classed('fa fa-folder-open fa-fw', true)
      .attr('title', 'Play from music collection')
      .on('click', () => {
        mp3dialog.chooseMp3()
            .then(url => opts.startPlaybackFrom(url))
            .catch(e => {
              console.log('Error in mp3 dialog', e);
            });
      });
  const i2 = d.append('i')
      .classed('fa fa-ellipsis-h fa-fw', true)
      .attr('title', 'Pick other audio source')
      .on('click', () => {
        mp3dialog
            .showModal({
              title : 'Pick audio source',
              resolve : v => {
                console.log('Pick audio resolved', v);
                if (v.dmp3) {
                  opts.startDecodeFrom(v.dmp3);
                } else if (v.tone) {
                  opts.tone(v.tone);
                }
              }
            })
            .appendH2('Decoded MP3')
            .appendP('Audio samples stored locally (no MP3 server dependency), decoded into a buffer before playback.')
            .appendResolvingList([
              { dmp3 : 'data/viper.mp3' , t1 : 'Viper', t2 : 'for Web Audio examples project' },
              // track credit:
              // Outfoxing the Fox by Kevin MacLeod under Creative Commons
              { dmp3 : 'data/outfoxing.mp3' , t1 : 'Outfoxing the fox', t2 : 'by Kevin MacLeod (incompetech.com)' },
              // track credit:
              // RetroFuture Dirty Kevin MacLeod (incompetech.com)
              // Licensed under Creative Commons: By Attribution 3.0 License http://creativecommons.org/ licenses/by/3.0/
              { dmp3 : 'data/retrofuturedirty.mp3' , t1 : 'RetroFuture dirty', t2 : 'by Kevin MacLeod (incompetech.com)' },
              // track credit:
              // "Sneaky Snitch" Kevin MacLeod (incompetech.com)
              // Licensed under Creative Commons: By Attribution 4.0 License http://creativecommons.org/licenses/by/4.0/
              { dmp3 : 'data/sneakysnitch.mp3' , t1 : 'Sneaky Snitch', t2 : 'by Kevin MacLeod (incompetech.com)' }
            ], d => d.t1, d => d.t2)
            .appendH2('Fixed tones')
            .appendP('Pure sine wave generated by oscillator node.')
            .appendResolvingList([
              { tone : 55 },
              { tone : 110 },
              { tone : 220 },
              { tone : 440 },
              { tone : 1000 },
              { tone : 2000 },
              { tone : 3000 }
            ], d => `${d.tone} Hz`);
      });

  const i3 = d.append('i')
      .classed('fa fa-stop fa-fw', true)
      .attr('title', 'Stop playback')
      .on('click', () => {
        opts.stop();
      });
  i3.classed('disabled', true);

  const ret = {
    stopEnabled : v => i3.classed('disabled', !v)
  };
  return ret;
}

/**
 * Add playback.
 *
 * parentD3: D3 selection of parent element for buttons
 * playerParentD3: D3 selection of parent element for audio element and additional seek controls
 * opts: callbacks called with component facade when audio context is initiated (inside a user action)
 */
export function addSimplePlayback(parentD3, playerParentD3, msgD3, opts) {
  const ctrls = addPlaybackControls(parentD3, {
    startPlaybackFrom : url => audio(url),
    startDecodeFrom : url => load(url),
    tone : f => tone(f),
    stop : () => stop()
  });

  /*
  const div = parentD3.append('div').classed('playback-controls', true);
  const msgDiv = div.append('div').classed('message', true)
  const msg1 = msgDiv.append('span').text('Click on a play button');
  const msg2 = msgDiv.append('span');
  */

  var audioContext;
  var sourceNode;
  var sampleRate;
  var playing = false;

  const events = {
    contextCreated : ed.ed(),
    playbackStarted : ed.ed(),
    playbackStopped : ed.ed(),
    playbackPaused : ed.ed(),
    playbackResumed : ed.ed()
  };

  function ensureAudioContext() {
    if (!audioContext) {
      audioContext = new AudioContext();
    }
  }

  function disableButtons() {
    ctrls.stopEnabled(true);
  }

  function enableButtons() {
    ctrls.stopEnabled(false);
  }

  var useAudio = false;

  var a;
  var adiv;
  var apaused;
  var lastPlaybackInfo;
  var astop;

  function audio(url) {
    ret.ensureStop(true);
    message(`Start playing from ${decodeURI(url)}`);
    disableButtons();
    adiv = playerParentD3.append('div').classed('playback-player', true)
    a = adiv.append('audio').attr('crossorigin', 'anonymous').attr('controls', true);
    apaused = false;
    astop = false;

    a.node().onpause = e => {
      if (astop) {
        return;
      }
      apaused = true;
      events.playbackPaused(ret);
    };
    a.node().onplay = e => {
      if (!apaused) {
        return;
      }
      apaused = false;
      events.playbackResumed(ret);
    };
    a.attr('src', url);


    const xctd = adiv.append('div').classed('playback-extra-controls spaced', true);
    xctd.append('i').classed('fa fa-caret-left fa-fw', true).on('click', () => {
      const ct = a.node().currentTime;
      a.node().currentTime = Math.max(0, ct - 3);
      a.node().play();
    });

    xctd.append('i').classed('fa fa-caret-right fa-fw', true).on('click', () => {
      const ct = a.node().currentTime;
      a.node().currentTime = ct + 3;
      a.node().play();
    });

    //audioContext = new AudioContext();
    ensureAudioContext();

    sourceNode = audioContext.createMediaElementSource(a.node());
    sourceNode.connect(audioContext.destination);

    sampleRate = audioContext.sampleRate;
    if (opts.build) {
      opts.build(ret);
    }


    useAudio = true;

    lastPlaybackInfo = {
      audio : 'MP3',
      url : url
    };

    ret.start();

  }

  function tone(f) {
    ret.ensureStop(true);
    message(`Playing ${f} Hz sinewave`);
    disableButtons();

    // A user interaction happened we can create the audioContext
    // audioContext = new AudioContext();
    ensureAudioContext();

    sourceNode = audioContext.createOscillator();
    sourceNode.frequency.setValueAtTime(f, audioContext.currentTime);
    sourceNode.connect(audioContext.destination);
    sampleRate = audioContext.sampleRate;

    if (opts.build) {
      opts.build(ret);
    }

    lastPlaybackInfo = {
      audio : `${f} z sinewave`
    };

    ret.start();
  }

  function stop(silent) {
    lastPlaybackInfo = undefined;
    astop = true;
    if (!playing) {
      throw new Error('Not playing');
    }
    playing = false;
    apaused = false;
    if (useAudio) {
      useAudio = false;
      a.node().pause();
      adiv.remove();
      a = undefined;
      adiv = undefined;
    } else {
      sourceNode.stop(0);
    }
    enableButtons();
    if (!silent) {
      message2('Playback stopped');
    }
    events.playbackStopped(ret);

  }

  var lastM1;

  function message(message) {
    lastM1 = message;
    if (msgD3) {
      msgD3.text(message);
    } else {
      notes.top(message);
    }
    //msg1.text(message);
     // msg2.text('');
  }

  function message2(message) {
    if (msgD3) {
      msgD3.text(lastM1 + ' | ' + message);
    } else {
      notes.top(message);
    }
    // msg2.text(message);
  }


  function load(url) {
    ret.ensureStop(true);

    disableButtons();

    // A user interaction happened we can create the audioContext
    // audioContext = new AudioContext();
    ensureAudioContext();

    message(`Loading audio from ${url}`);

    fetch(url)
        .then(response => response.arrayBuffer())
        .then(downloadedBuffer => {
          message(`Loaded ${downloadedBuffer.byteLength} bytes, start decoding`);
          return audioContext.decodeAudioData(downloadedBuffer)
        })
        .then((decodedBuffer) => {
          sampleRate = decodedBuffer.sampleRate;
          message(`Decoded ${u.niceRound(decodedBuffer.duration)} s, ${decodedBuffer.numberOfChannels} ch, with sample rate ${decodedBuffer.sampleRate}.`)

          sourceNode = new AudioBufferSourceNode(audioContext, {
            buffer: decodedBuffer,
            loop: true,
          });
          sourceNode.connect(audioContext.destination);

        })
        .then(() => {
          if (opts.build) {
            opts.build(ret);
          }
          lastPlaybackInfo = {
            audio : 'MP3 (decoded from buffer)',
            url : url
          };

          ret.start();
        });
  }

  // TODO: reuse context, see https://developer.mozilla.org/en-US/docs/Web/API/AudioContext
  // > It's recommended to create one AudioContext and reuse it instead of initializing a new one each time



  const ret = {
    // playback events will be called with an argument of "ret"
    onPlaybackStarted : h => {
      events.playbackStarted.add(h);
      return ret;
    },
    onPlaybackStopped : h => {
      events.playbackStopped.add(h);
      return ret;
    },
    onPlaybackPaused : h => {
      events.playbackPaused.add(h);
      return ret;
    },
    onPlaybackResumed : h => {
      events.playbackResumed.add(h);
      return ret;
    },
    tryToCreateAudioContext : () => ensureAudioContext(),
    startPlaybackFrom : url => {
      console.log('Start playback from', url)
      if (playing) {
        stop();
      }
      audio(url);
    },
    start : () => {
      if (playing) {
        throw new Error('Already playing');
      }
      if (!sourceNode) {
        throw new Error('No audio loaded');
      }

      if (useAudio) {
        a.node().play();
      }  else {
        sourceNode.start(0);
      }


      playing = true;
      message2('Playback started');
      events.playbackStarted(ret);
    },
    ensureStop : (silent) => {
      if (!playing) {
        return;
      }
      stop(silent);
    },
    newAnalyserNode : () => {
      if (!audioContext) {
        throw new Error('No audio loaded');
      }
      // see https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode
      const analyserNode = new AnalyserNode(audioContext);
      sourceNode.connect(analyserNode);
      return analyserNode;
    },
    sampleRate : () => sampleRate,
    getCurrentTime : () => {
      if (!playing) {
        return 0;
      }
      if (useAudio) {
        return a.node().currentTime;
      }
      return 0;
    },
    getDuration : () => {
      if (!playing) {
        return 0;
      }
      if (useAudio) {
        const d = a.node().duration;
        if (d) {
          return d;
        }
      }
      return 0;
    },
    getPlaybackInfo : () => {
      if (!playing) {
        return undefined;
      }
      lastPlaybackInfo.paused = ret.isPaused();
      return lastPlaybackInfo;
    },
    isPlaying : () => playing,
    isPaused : () => apaused,
    pause : () => {
      if (!playing || !useAudio) {
        return;
      }
      a.node().pause();
    },
    resume : () => {
      if (!playing || !useAudio) {
        return;
      }
      a.node().play();
    },
    seek : t => {
      // console.log('Seek to ' + t);
      if (t < 0 || !playing || !useAudio) {
        return;
      }

      a.node().currentTime = t;

      return ret;
    },
    seekRelative : d => {
      // console.log('Seek to ' + t);
      if (!d || !playing || !useAudio) {
        return;
      }
      const t = a.node().currentTime;
      if (!t) {
        return;
      }
      const nt = t + d;
      a.node().currentTime = nt;
      return ret;
    }
  };
  return ret;
}
